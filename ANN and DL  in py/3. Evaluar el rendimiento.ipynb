{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><font color=\"#113D68\" size=6>Deep Learning con Python y Keras</font></h1>\n",
    "\n",
    "<h1><font color=\"#113D68\" size=5>Parte 3. Multilayer Perceptron</font></h1>\n",
    "\n",
    "<h1><font color=\"#113D68\" size=4>3. Evaluar el rendimiento</font></h1>\n",
    "\n",
    "<br><br>\n",
    "<div style=\"text-align: right\">\n",
    "<font color=\"#113D68\" size=3>Manuel Castillo Cara</font><br>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id=\"indice\"></a>\n",
    "<h2><font color=\"#004D7F\" size=5>Índice</font></h2>\n",
    "\n",
    "* [0. Contexto](#section0)\n",
    "* [1. Evaluar empíricamente las configuraciones de red](#section1)\n",
    "* [2. División de datos](#section2)\n",
    "    * [2.1. Verificación automática](#section2.1)\n",
    "    * [2.2. Verificación manual](#section2.2)\n",
    "* [3. Validación cruzada](#section3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id=\"section0\"></a>\n",
    "# <font color=\"#004D7F\" size=6> 0. Contexto</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta lección, descubrirá algunas formas que puede utilizar para evaluar el rendimiento del modelo. Después de completar esta lección, sabrá:\n",
    "* Cómo evaluar un modelo utilizando un conjunto de datos de verificación automática.\n",
    "* Cómo evaluar un modelo utilizando un conjunto de datos de verificación manual.\n",
    "* Cómo evaluar un modelo mediante la validación cruzada de k-fold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "# Eliminar warning\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<div style=\"text-align: right\"> <font size=5> <a href=\"#indice\"><i class=\"fa fa-arrow-circle-up\" aria-hidden=\"true\" style=\"color:#004D7F\"></i></a></font></div>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section1\"></a>\n",
    "# <font color=\"#004D7F\" size=6>1. Evaluar empíricamente las configuraciones de red</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A la hora de evaluar modelos tenemos que tener en cuenta decisiones de nivel inferior como la elección de la función de pérdida, funciones de activación, procedimiento de optimización y número de épocas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<div style=\"text-align: right\"> <font size=5> <a href=\"#indice\"><i class=\"fa fa-arrow-circle-up\" aria-hidden=\"true\" style=\"color:#004D7F\"></i></a></font></div>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section2\"></a>\n",
    "# <font color=\"#004D7F\" size=6>2. División de datos</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es común utilizar una simple separación de datos en conjuntos de datos de entrenamiento y validación. Keras proporciona dos formas convenientes de evaluar sus algoritmos de Deep Learning de esta manera:\n",
    "1. Utilice un conjunto de datos de verificación automática.\n",
    "2. Utilice un conjunto de datos de verificación manual."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section2.1\"></a>\n",
    "# <font color=\"#004D7F\" size=5>2.1. Verificación automática</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras puede separar una parte de sus datos de entrenamiento/validación y evaluar el rendimiento del modelo en cada época. Puede hacer esto configurando el argumento `validation_split` en la función `fit()` en un porcentaje del tamaño de su conjunto de datos de entrenamiento. \n",
    "\n",
    "Veamos un ejemplo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "52/52 [==============================] - 0s 8ms/step - loss: 58.5588 - accuracy: 0.4066 - val_loss: 4.5116 - val_accuracy: 0.6378\n",
      "Epoch 2/150\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 6.3825 - accuracy: 0.5778 - val_loss: 4.0931 - val_accuracy: 0.6339\n",
      "Epoch 3/150\n",
      "52/52 [==============================] - 0s 945us/step - loss: 4.2595 - accuracy: 0.6148 - val_loss: 3.7404 - val_accuracy: 0.6457\n",
      "Epoch 4/150\n",
      "52/52 [==============================] - 0s 901us/step - loss: 3.9639 - accuracy: 0.5895 - val_loss: 3.5351 - val_accuracy: 0.6299\n",
      "Epoch 5/150\n",
      "52/52 [==============================] - 0s 948us/step - loss: 3.7219 - accuracy: 0.6167 - val_loss: 3.2899 - val_accuracy: 0.6417\n",
      "Epoch 6/150\n",
      "52/52 [==============================] - 0s 987us/step - loss: 3.4623 - accuracy: 0.6167 - val_loss: 3.0745 - val_accuracy: 0.6181\n",
      "Epoch 7/150\n",
      "52/52 [==============================] - 0s 898us/step - loss: 3.3172 - accuracy: 0.6265 - val_loss: 2.9992 - val_accuracy: 0.6142\n",
      "Epoch 8/150\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 3.1682 - accuracy: 0.6304 - val_loss: 2.6518 - val_accuracy: 0.6339\n",
      "Epoch 9/150\n",
      "52/52 [==============================] - 0s 946us/step - loss: 2.9208 - accuracy: 0.5934 - val_loss: 2.5291 - val_accuracy: 0.6220\n",
      "Epoch 10/150\n",
      "52/52 [==============================] - 0s 898us/step - loss: 2.4325 - accuracy: 0.6187 - val_loss: 2.2698 - val_accuracy: 0.6378\n",
      "Epoch 11/150\n",
      "52/52 [==============================] - 0s 943us/step - loss: 2.1431 - accuracy: 0.6401 - val_loss: 2.6639 - val_accuracy: 0.6575\n",
      "Epoch 12/150\n",
      "52/52 [==============================] - 0s 920us/step - loss: 2.1581 - accuracy: 0.6304 - val_loss: 2.0261 - val_accuracy: 0.6220\n",
      "Epoch 13/150\n",
      "52/52 [==============================] - 0s 913us/step - loss: 1.9173 - accuracy: 0.6498 - val_loss: 1.7607 - val_accuracy: 0.6417\n",
      "Epoch 14/150\n",
      "52/52 [==============================] - 0s 895us/step - loss: 2.0086 - accuracy: 0.6206 - val_loss: 1.6654 - val_accuracy: 0.6457\n",
      "Epoch 15/150\n",
      "52/52 [==============================] - 0s 911us/step - loss: 1.6663 - accuracy: 0.6479 - val_loss: 1.5415 - val_accuracy: 0.6378\n",
      "Epoch 16/150\n",
      "52/52 [==============================] - 0s 946us/step - loss: 1.4309 - accuracy: 0.6459 - val_loss: 1.4245 - val_accuracy: 0.6181\n",
      "Epoch 17/150\n",
      "52/52 [==============================] - 0s 915us/step - loss: 1.4122 - accuracy: 0.6342 - val_loss: 2.0900 - val_accuracy: 0.4882\n",
      "Epoch 18/150\n",
      "52/52 [==============================] - 0s 918us/step - loss: 1.3728 - accuracy: 0.5973 - val_loss: 1.2054 - val_accuracy: 0.6024\n",
      "Epoch 19/150\n",
      "52/52 [==============================] - 0s 945us/step - loss: 1.2082 - accuracy: 0.6226 - val_loss: 1.1047 - val_accuracy: 0.6260\n",
      "Epoch 20/150\n",
      "52/52 [==============================] - 0s 940us/step - loss: 1.2377 - accuracy: 0.5953 - val_loss: 1.1520 - val_accuracy: 0.6732\n",
      "Epoch 21/150\n",
      "52/52 [==============================] - 0s 915us/step - loss: 1.2110 - accuracy: 0.6226 - val_loss: 1.0778 - val_accuracy: 0.5984\n",
      "Epoch 22/150\n",
      "52/52 [==============================] - 0s 959us/step - loss: 1.1941 - accuracy: 0.6265 - val_loss: 1.0416 - val_accuracy: 0.5748\n",
      "Epoch 23/150\n",
      "52/52 [==============================] - 0s 984us/step - loss: 1.1974 - accuracy: 0.6070 - val_loss: 0.9859 - val_accuracy: 0.6063\n",
      "Epoch 24/150\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 1.2330 - accuracy: 0.6245 - val_loss: 1.1883 - val_accuracy: 0.5906\n",
      "Epoch 25/150\n",
      "52/52 [==============================] - 0s 917us/step - loss: 1.2721 - accuracy: 0.6265 - val_loss: 1.7257 - val_accuracy: 0.6457\n",
      "Epoch 26/150\n",
      "52/52 [==============================] - 0s 945us/step - loss: 1.1147 - accuracy: 0.6206 - val_loss: 1.3202 - val_accuracy: 0.6181\n",
      "Epoch 27/150\n",
      "52/52 [==============================] - 0s 968us/step - loss: 1.2089 - accuracy: 0.5875 - val_loss: 1.8160 - val_accuracy: 0.4803\n",
      "Epoch 28/150\n",
      "52/52 [==============================] - 0s 926us/step - loss: 1.2468 - accuracy: 0.5895 - val_loss: 0.9827 - val_accuracy: 0.6339\n",
      "Epoch 29/150\n",
      "52/52 [==============================] - 0s 942us/step - loss: 0.9922 - accuracy: 0.6518 - val_loss: 1.1444 - val_accuracy: 0.5787\n",
      "Epoch 30/150\n",
      "52/52 [==============================] - 0s 956us/step - loss: 1.0587 - accuracy: 0.6167 - val_loss: 0.8970 - val_accuracy: 0.6102\n",
      "Epoch 31/150\n",
      "52/52 [==============================] - 0s 944us/step - loss: 0.8868 - accuracy: 0.6245 - val_loss: 1.4081 - val_accuracy: 0.4961\n",
      "Epoch 32/150\n",
      "52/52 [==============================] - 0s 964us/step - loss: 0.9511 - accuracy: 0.6498 - val_loss: 1.0694 - val_accuracy: 0.5591\n",
      "Epoch 33/150\n",
      "52/52 [==============================] - 0s 937us/step - loss: 0.9539 - accuracy: 0.6556 - val_loss: 1.1261 - val_accuracy: 0.6102\n",
      "Epoch 34/150\n",
      "52/52 [==============================] - 0s 978us/step - loss: 0.9951 - accuracy: 0.6148 - val_loss: 0.8631 - val_accuracy: 0.5945\n",
      "Epoch 35/150\n",
      "52/52 [==============================] - 0s 994us/step - loss: 1.0673 - accuracy: 0.6167 - val_loss: 0.9497 - val_accuracy: 0.5591\n",
      "Epoch 36/150\n",
      "52/52 [==============================] - 0s 920us/step - loss: 0.8843 - accuracy: 0.6576 - val_loss: 0.8513 - val_accuracy: 0.5906\n",
      "Epoch 37/150\n",
      "52/52 [==============================] - 0s 956us/step - loss: 0.8951 - accuracy: 0.6537 - val_loss: 0.8406 - val_accuracy: 0.6260\n",
      "Epoch 38/150\n",
      "52/52 [==============================] - 0s 923us/step - loss: 0.8652 - accuracy: 0.6323 - val_loss: 1.0401 - val_accuracy: 0.5433\n",
      "Epoch 39/150\n",
      "52/52 [==============================] - 0s 955us/step - loss: 0.9404 - accuracy: 0.6167 - val_loss: 1.0786 - val_accuracy: 0.6063\n",
      "Epoch 40/150\n",
      "52/52 [==============================] - 0s 972us/step - loss: 0.9379 - accuracy: 0.6362 - val_loss: 0.8138 - val_accuracy: 0.6024\n",
      "Epoch 41/150\n",
      "52/52 [==============================] - 0s 974us/step - loss: 1.0767 - accuracy: 0.6342 - val_loss: 0.8273 - val_accuracy: 0.6063\n",
      "Epoch 42/150\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.9621 - accuracy: 0.6323 - val_loss: 0.7890 - val_accuracy: 0.6260\n",
      "Epoch 43/150\n",
      "52/52 [==============================] - 0s 945us/step - loss: 0.7617 - accuracy: 0.6401 - val_loss: 0.8202 - val_accuracy: 0.6024\n",
      "Epoch 44/150\n",
      "52/52 [==============================] - 0s 997us/step - loss: 0.8392 - accuracy: 0.6226 - val_loss: 1.0111 - val_accuracy: 0.5472\n",
      "Epoch 45/150\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.7982 - accuracy: 0.6420 - val_loss: 0.7843 - val_accuracy: 0.6260\n",
      "Epoch 46/150\n",
      "52/52 [==============================] - 0s 978us/step - loss: 1.1279 - accuracy: 0.6051 - val_loss: 1.0253 - val_accuracy: 0.5433\n",
      "Epoch 47/150\n",
      "52/52 [==============================] - 0s 921us/step - loss: 0.9774 - accuracy: 0.6206 - val_loss: 0.9223 - val_accuracy: 0.6339\n",
      "Epoch 48/150\n",
      "52/52 [==============================] - 0s 933us/step - loss: 0.8835 - accuracy: 0.6206 - val_loss: 0.8325 - val_accuracy: 0.5748\n",
      "Epoch 49/150\n",
      "52/52 [==============================] - 0s 938us/step - loss: 1.1395 - accuracy: 0.6012 - val_loss: 1.0897 - val_accuracy: 0.5630\n",
      "Epoch 50/150\n",
      "52/52 [==============================] - 0s 913us/step - loss: 1.1557 - accuracy: 0.6459 - val_loss: 0.8106 - val_accuracy: 0.6220\n",
      "Epoch 51/150\n",
      "52/52 [==============================] - 0s 909us/step - loss: 0.7137 - accuracy: 0.6537 - val_loss: 0.8730 - val_accuracy: 0.6220\n",
      "Epoch 52/150\n",
      "52/52 [==============================] - 0s 909us/step - loss: 0.7449 - accuracy: 0.6459 - val_loss: 0.7562 - val_accuracy: 0.6299\n",
      "Epoch 53/150\n",
      "52/52 [==============================] - 0s 941us/step - loss: 1.0191 - accuracy: 0.5973 - val_loss: 1.2289 - val_accuracy: 0.6457\n",
      "Epoch 54/150\n",
      "52/52 [==============================] - 0s 937us/step - loss: 0.9044 - accuracy: 0.6304 - val_loss: 1.6919 - val_accuracy: 0.4528\n",
      "Epoch 55/150\n",
      "52/52 [==============================] - 0s 902us/step - loss: 0.9048 - accuracy: 0.6304 - val_loss: 0.7318 - val_accuracy: 0.6339\n",
      "Epoch 56/150\n",
      "52/52 [==============================] - 0s 886us/step - loss: 0.7021 - accuracy: 0.6479 - val_loss: 0.7939 - val_accuracy: 0.6378\n",
      "Epoch 57/150\n",
      "52/52 [==============================] - 0s 913us/step - loss: 0.7268 - accuracy: 0.6595 - val_loss: 1.4486 - val_accuracy: 0.6417\n",
      "Epoch 58/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 [==============================] - 0s 908us/step - loss: 0.8928 - accuracy: 0.6381 - val_loss: 1.3358 - val_accuracy: 0.4685\n",
      "Epoch 59/150\n",
      "52/52 [==============================] - 0s 917us/step - loss: 1.1781 - accuracy: 0.6128 - val_loss: 0.7684 - val_accuracy: 0.5945\n",
      "Epoch 60/150\n",
      "52/52 [==============================] - 0s 893us/step - loss: 0.6650 - accuracy: 0.6751 - val_loss: 0.6974 - val_accuracy: 0.6535\n",
      "Epoch 61/150\n",
      "52/52 [==============================] - 0s 903us/step - loss: 0.7067 - accuracy: 0.6381 - val_loss: 0.7120 - val_accuracy: 0.6575\n",
      "Epoch 62/150\n",
      "52/52 [==============================] - 0s 903us/step - loss: 0.7496 - accuracy: 0.6751 - val_loss: 0.8310 - val_accuracy: 0.6063\n",
      "Epoch 63/150\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.6431 - accuracy: 0.6576 - val_loss: 0.7404 - val_accuracy: 0.6299\n",
      "Epoch 64/150\n",
      "52/52 [==============================] - 0s 895us/step - loss: 0.8943 - accuracy: 0.6284 - val_loss: 0.7673 - val_accuracy: 0.6535\n",
      "Epoch 65/150\n",
      "52/52 [==============================] - 0s 897us/step - loss: 0.8068 - accuracy: 0.6498 - val_loss: 0.6953 - val_accuracy: 0.6496\n",
      "Epoch 66/150\n",
      "52/52 [==============================] - 0s 933us/step - loss: 1.1664 - accuracy: 0.6265 - val_loss: 0.8169 - val_accuracy: 0.6260\n",
      "Epoch 67/150\n",
      "52/52 [==============================] - 0s 957us/step - loss: 0.7109 - accuracy: 0.6634 - val_loss: 0.7344 - val_accuracy: 0.6378\n",
      "Epoch 68/150\n",
      "52/52 [==============================] - 0s 940us/step - loss: 0.6626 - accuracy: 0.6498 - val_loss: 0.8425 - val_accuracy: 0.6181\n",
      "Epoch 69/150\n",
      "52/52 [==============================] - 0s 940us/step - loss: 0.7196 - accuracy: 0.6673 - val_loss: 0.7679 - val_accuracy: 0.6299\n",
      "Epoch 70/150\n",
      "52/52 [==============================] - 0s 946us/step - loss: 0.7891 - accuracy: 0.6420 - val_loss: 0.8389 - val_accuracy: 0.5787\n",
      "Epoch 71/150\n",
      "52/52 [==============================] - 0s 914us/step - loss: 0.7663 - accuracy: 0.6556 - val_loss: 0.8156 - val_accuracy: 0.5945\n",
      "Epoch 72/150\n",
      "52/52 [==============================] - 0s 934us/step - loss: 0.7249 - accuracy: 0.6362 - val_loss: 0.6906 - val_accuracy: 0.6457\n",
      "Epoch 73/150\n",
      "52/52 [==============================] - 0s 901us/step - loss: 0.6447 - accuracy: 0.6693 - val_loss: 0.8077 - val_accuracy: 0.6417\n",
      "Epoch 74/150\n",
      "52/52 [==============================] - 0s 912us/step - loss: 0.6797 - accuracy: 0.6693 - val_loss: 0.6880 - val_accuracy: 0.6299\n",
      "Epoch 75/150\n",
      "52/52 [==============================] - 0s 906us/step - loss: 0.6808 - accuracy: 0.6556 - val_loss: 0.6990 - val_accuracy: 0.6614\n",
      "Epoch 76/150\n",
      "52/52 [==============================] - 0s 895us/step - loss: 0.7147 - accuracy: 0.6556 - val_loss: 0.7391 - val_accuracy: 0.6339\n",
      "Epoch 77/150\n",
      "52/52 [==============================] - 0s 921us/step - loss: 0.7789 - accuracy: 0.6459 - val_loss: 0.8004 - val_accuracy: 0.5748\n",
      "Epoch 78/150\n",
      "52/52 [==============================] - 0s 978us/step - loss: 1.0837 - accuracy: 0.6284 - val_loss: 1.0184 - val_accuracy: 0.6575\n",
      "Epoch 79/150\n",
      "52/52 [==============================] - 0s 941us/step - loss: 0.7597 - accuracy: 0.6654 - val_loss: 1.0434 - val_accuracy: 0.5354\n",
      "Epoch 80/150\n",
      "52/52 [==============================] - 0s 957us/step - loss: 0.7319 - accuracy: 0.6712 - val_loss: 0.9065 - val_accuracy: 0.5709\n",
      "Epoch 81/150\n",
      "52/52 [==============================] - 0s 863us/step - loss: 0.6549 - accuracy: 0.6829 - val_loss: 0.6728 - val_accuracy: 0.6693\n",
      "Epoch 82/150\n",
      "52/52 [==============================] - 0s 887us/step - loss: 0.6275 - accuracy: 0.7082 - val_loss: 0.6609 - val_accuracy: 0.6614\n",
      "Epoch 83/150\n",
      "52/52 [==============================] - 0s 895us/step - loss: 0.7689 - accuracy: 0.6537 - val_loss: 0.6669 - val_accuracy: 0.6535\n",
      "Epoch 84/150\n",
      "52/52 [==============================] - 0s 964us/step - loss: 0.7061 - accuracy: 0.6887 - val_loss: 1.1335 - val_accuracy: 0.4921\n",
      "Epoch 85/150\n",
      "52/52 [==============================] - 0s 905us/step - loss: 0.7296 - accuracy: 0.6459 - val_loss: 0.9101 - val_accuracy: 0.6024\n",
      "Epoch 86/150\n",
      "52/52 [==============================] - 0s 907us/step - loss: 0.9101 - accuracy: 0.6634 - val_loss: 0.8143 - val_accuracy: 0.6260\n",
      "Epoch 87/150\n",
      "52/52 [==============================] - 0s 945us/step - loss: 0.7815 - accuracy: 0.6615 - val_loss: 0.7858 - val_accuracy: 0.6063\n",
      "Epoch 88/150\n",
      "52/52 [==============================] - 0s 926us/step - loss: 0.8603 - accuracy: 0.6518 - val_loss: 0.8480 - val_accuracy: 0.5748\n",
      "Epoch 89/150\n",
      "52/52 [==============================] - 0s 940us/step - loss: 0.8318 - accuracy: 0.6634 - val_loss: 0.8160 - val_accuracy: 0.5945\n",
      "Epoch 90/150\n",
      "52/52 [==============================] - 0s 960us/step - loss: 0.8382 - accuracy: 0.6498 - val_loss: 0.6883 - val_accuracy: 0.6535\n",
      "Epoch 91/150\n",
      "52/52 [==============================] - 0s 868us/step - loss: 0.8933 - accuracy: 0.6401 - val_loss: 0.7910 - val_accuracy: 0.6260\n",
      "Epoch 92/150\n",
      "52/52 [==============================] - 0s 907us/step - loss: 0.7204 - accuracy: 0.6518 - val_loss: 0.6395 - val_accuracy: 0.6535\n",
      "Epoch 93/150\n",
      "52/52 [==============================] - 0s 894us/step - loss: 0.6115 - accuracy: 0.7043 - val_loss: 0.6364 - val_accuracy: 0.6732\n",
      "Epoch 94/150\n",
      "52/52 [==============================] - 0s 916us/step - loss: 0.6520 - accuracy: 0.6829 - val_loss: 0.6997 - val_accuracy: 0.6339\n",
      "Epoch 95/150\n",
      "52/52 [==============================] - 0s 995us/step - loss: 0.6196 - accuracy: 0.6907 - val_loss: 0.7672 - val_accuracy: 0.5984\n",
      "Epoch 96/150\n",
      "52/52 [==============================] - 0s 937us/step - loss: 0.9712 - accuracy: 0.6381 - val_loss: 0.8848 - val_accuracy: 0.6535\n",
      "Epoch 97/150\n",
      "52/52 [==============================] - 0s 889us/step - loss: 0.6613 - accuracy: 0.6809 - val_loss: 0.9151 - val_accuracy: 0.6181\n",
      "Epoch 98/150\n",
      "52/52 [==============================] - 0s 880us/step - loss: 0.7041 - accuracy: 0.6595 - val_loss: 0.8276 - val_accuracy: 0.6299\n",
      "Epoch 99/150\n",
      "52/52 [==============================] - 0s 891us/step - loss: 0.5920 - accuracy: 0.7101 - val_loss: 0.6306 - val_accuracy: 0.6693\n",
      "Epoch 100/150\n",
      "52/52 [==============================] - 0s 916us/step - loss: 0.6127 - accuracy: 0.6946 - val_loss: 0.6936 - val_accuracy: 0.6299\n",
      "Epoch 101/150\n",
      "52/52 [==============================] - 0s 913us/step - loss: 0.6960 - accuracy: 0.6829 - val_loss: 0.6363 - val_accuracy: 0.6811\n",
      "Epoch 102/150\n",
      "52/52 [==============================] - 0s 888us/step - loss: 0.6444 - accuracy: 0.7101 - val_loss: 0.7187 - val_accuracy: 0.6378\n",
      "Epoch 103/150\n",
      "52/52 [==============================] - 0s 938us/step - loss: 0.5862 - accuracy: 0.7179 - val_loss: 0.9446 - val_accuracy: 0.5709\n",
      "Epoch 104/150\n",
      "52/52 [==============================] - 0s 961us/step - loss: 0.9793 - accuracy: 0.6440 - val_loss: 0.6936 - val_accuracy: 0.6575\n",
      "Epoch 105/150\n",
      "52/52 [==============================] - 0s 949us/step - loss: 0.6786 - accuracy: 0.7062 - val_loss: 1.0540 - val_accuracy: 0.5354\n",
      "Epoch 106/150\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.6882 - accuracy: 0.6926 - val_loss: 0.6773 - val_accuracy: 0.6693\n",
      "Epoch 107/150\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.6773 - accuracy: 0.6498 - val_loss: 0.7941 - val_accuracy: 0.6260\n",
      "Epoch 108/150\n",
      "52/52 [==============================] - 0s 963us/step - loss: 0.7010 - accuracy: 0.6556 - val_loss: 0.6749 - val_accuracy: 0.6614\n",
      "Epoch 109/150\n",
      "52/52 [==============================] - 0s 989us/step - loss: 0.6530 - accuracy: 0.6848 - val_loss: 0.7577 - val_accuracy: 0.6220\n",
      "Epoch 110/150\n",
      "52/52 [==============================] - 0s 918us/step - loss: 0.9536 - accuracy: 0.6187 - val_loss: 0.7020 - val_accuracy: 0.6496\n",
      "Epoch 111/150\n",
      "52/52 [==============================] - 0s 945us/step - loss: 0.6023 - accuracy: 0.7257 - val_loss: 0.6882 - val_accuracy: 0.6575\n",
      "Epoch 112/150\n",
      "52/52 [==============================] - 0s 908us/step - loss: 0.6485 - accuracy: 0.6965 - val_loss: 0.6326 - val_accuracy: 0.6850\n",
      "Epoch 113/150\n",
      "52/52 [==============================] - 0s 915us/step - loss: 0.7656 - accuracy: 0.6770 - val_loss: 1.4601 - val_accuracy: 0.4764\n",
      "Epoch 114/150\n",
      "52/52 [==============================] - 0s 925us/step - loss: 1.0515 - accuracy: 0.6362 - val_loss: 1.4437 - val_accuracy: 0.6614\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 115/150\n",
      "52/52 [==============================] - 0s 922us/step - loss: 0.7940 - accuracy: 0.6595 - val_loss: 0.6334 - val_accuracy: 0.6693\n",
      "Epoch 116/150\n",
      "52/52 [==============================] - 0s 959us/step - loss: 0.6115 - accuracy: 0.7296 - val_loss: 0.7069 - val_accuracy: 0.6220\n",
      "Epoch 117/150\n",
      "52/52 [==============================] - 0s 978us/step - loss: 0.6493 - accuracy: 0.6868 - val_loss: 0.7600 - val_accuracy: 0.6220\n",
      "Epoch 118/150\n",
      "52/52 [==============================] - 0s 998us/step - loss: 0.6223 - accuracy: 0.7160 - val_loss: 0.8271 - val_accuracy: 0.6457\n",
      "Epoch 119/150\n",
      "52/52 [==============================] - 0s 944us/step - loss: 0.7299 - accuracy: 0.6381 - val_loss: 1.0125 - val_accuracy: 0.5787\n",
      "Epoch 120/150\n",
      "52/52 [==============================] - 0s 917us/step - loss: 0.7721 - accuracy: 0.6887 - val_loss: 0.8493 - val_accuracy: 0.6732\n",
      "Epoch 121/150\n",
      "52/52 [==============================] - 0s 909us/step - loss: 0.7382 - accuracy: 0.7004 - val_loss: 0.7112 - val_accuracy: 0.6811\n",
      "Epoch 122/150\n",
      "52/52 [==============================] - 0s 976us/step - loss: 0.6701 - accuracy: 0.7218 - val_loss: 0.6679 - val_accuracy: 0.6850\n",
      "Epoch 123/150\n",
      "52/52 [==============================] - 0s 972us/step - loss: 0.6802 - accuracy: 0.6984 - val_loss: 0.8058 - val_accuracy: 0.6811\n",
      "Epoch 124/150\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.6712 - accuracy: 0.7140 - val_loss: 0.7067 - val_accuracy: 0.6142\n",
      "Epoch 125/150\n",
      "52/52 [==============================] - 0s 959us/step - loss: 0.6772 - accuracy: 0.7160 - val_loss: 0.9642 - val_accuracy: 0.6575\n",
      "Epoch 126/150\n",
      "52/52 [==============================] - 0s 953us/step - loss: 0.8025 - accuracy: 0.6615 - val_loss: 0.7259 - val_accuracy: 0.6417\n",
      "Epoch 127/150\n",
      "52/52 [==============================] - 0s 931us/step - loss: 0.6454 - accuracy: 0.6848 - val_loss: 0.6777 - val_accuracy: 0.6693\n",
      "Epoch 128/150\n",
      "52/52 [==============================] - 0s 962us/step - loss: 0.7004 - accuracy: 0.6829 - val_loss: 0.8115 - val_accuracy: 0.6496\n",
      "Epoch 129/150\n",
      "52/52 [==============================] - 0s 907us/step - loss: 0.6638 - accuracy: 0.6965 - val_loss: 0.6533 - val_accuracy: 0.6693\n",
      "Epoch 130/150\n",
      "52/52 [==============================] - 0s 914us/step - loss: 0.6890 - accuracy: 0.6790 - val_loss: 0.6381 - val_accuracy: 0.6732\n",
      "Epoch 131/150\n",
      "52/52 [==============================] - 0s 903us/step - loss: 0.7947 - accuracy: 0.6595 - val_loss: 0.6845 - val_accuracy: 0.6732\n",
      "Epoch 132/150\n",
      "52/52 [==============================] - 0s 903us/step - loss: 0.7087 - accuracy: 0.6984 - val_loss: 0.6293 - val_accuracy: 0.6890\n",
      "Epoch 133/150\n",
      "52/52 [==============================] - 0s 904us/step - loss: 0.7081 - accuracy: 0.6984 - val_loss: 0.6389 - val_accuracy: 0.7205\n",
      "Epoch 134/150\n",
      "52/52 [==============================] - 0s 890us/step - loss: 0.7632 - accuracy: 0.6770 - val_loss: 0.7082 - val_accuracy: 0.6654\n",
      "Epoch 135/150\n",
      "52/52 [==============================] - 0s 938us/step - loss: 0.7179 - accuracy: 0.7101 - val_loss: 0.7462 - val_accuracy: 0.6654\n",
      "Epoch 136/150\n",
      "52/52 [==============================] - 0s 904us/step - loss: 1.0232 - accuracy: 0.6459 - val_loss: 0.9859 - val_accuracy: 0.6575\n",
      "Epoch 137/150\n",
      "52/52 [==============================] - 0s 899us/step - loss: 0.8326 - accuracy: 0.6907 - val_loss: 0.8175 - val_accuracy: 0.6614\n",
      "Epoch 138/150\n",
      "52/52 [==============================] - 0s 925us/step - loss: 0.8178 - accuracy: 0.6868 - val_loss: 0.7733 - val_accuracy: 0.6654\n",
      "Epoch 139/150\n",
      "52/52 [==============================] - 0s 913us/step - loss: 0.6982 - accuracy: 0.7101 - val_loss: 0.7292 - val_accuracy: 0.6220\n",
      "Epoch 140/150\n",
      "52/52 [==============================] - 0s 906us/step - loss: 0.6547 - accuracy: 0.7276 - val_loss: 0.6439 - val_accuracy: 0.7047\n",
      "Epoch 141/150\n",
      "52/52 [==============================] - 0s 908us/step - loss: 0.6449 - accuracy: 0.7237 - val_loss: 0.7145 - val_accuracy: 0.6693\n",
      "Epoch 142/150\n",
      "52/52 [==============================] - 0s 879us/step - loss: 0.6372 - accuracy: 0.7101 - val_loss: 0.6235 - val_accuracy: 0.6969\n",
      "Epoch 143/150\n",
      "52/52 [==============================] - 0s 910us/step - loss: 0.8359 - accuracy: 0.6848 - val_loss: 0.6073 - val_accuracy: 0.7165\n",
      "Epoch 144/150\n",
      "52/52 [==============================] - 0s 926us/step - loss: 0.6600 - accuracy: 0.7179 - val_loss: 0.7088 - val_accuracy: 0.6496\n",
      "Epoch 145/150\n",
      "52/52 [==============================] - 0s 925us/step - loss: 0.7191 - accuracy: 0.6887 - val_loss: 0.6397 - val_accuracy: 0.6969\n",
      "Epoch 146/150\n",
      "52/52 [==============================] - 0s 910us/step - loss: 0.7343 - accuracy: 0.7082 - val_loss: 0.8258 - val_accuracy: 0.6654\n",
      "Epoch 147/150\n",
      "52/52 [==============================] - 0s 941us/step - loss: 0.7239 - accuracy: 0.6868 - val_loss: 0.6323 - val_accuracy: 0.7008\n",
      "Epoch 148/150\n",
      "52/52 [==============================] - 0s 940us/step - loss: 0.5857 - accuracy: 0.7140 - val_loss: 0.6137 - val_accuracy: 0.7126\n",
      "Epoch 149/150\n",
      "52/52 [==============================] - 0s 962us/step - loss: 0.6088 - accuracy: 0.7121 - val_loss: 0.7243 - val_accuracy: 0.6693\n",
      "Epoch 150/150\n",
      "52/52 [==============================] - 0s 997us/step - loss: 0.6452 - accuracy: 0.7004 - val_loss: 0.7111 - val_accuracy: 0.7047\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1d97c2b1430>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MLP with automatic validation set\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import numpy as np\n",
    "\n",
    "# load pima indians dataset\n",
    "ruta = \"C:/Users/Maria Luisa/OneDrive/Documentos/Cursos/DeepLearningConPythonyKerasRedesNeuronalesAvanzado/Datasets/pima-indians-diabetes.csv\"\n",
    "dataset = np.loadtxt(ruta, delimiter = ',')\n",
    "\n",
    "# split into input (X) and output (Y) variables\n",
    "X = dataset[:, 0:8]\n",
    "y = dataset[:,8]\n",
    "\n",
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim = 8, activation = 'relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation= 'sigmoid'))\n",
    "\n",
    "# Compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer = 'adam', metrics= ['accuracy'])\n",
    "\n",
    "# Fit the model\n",
    "model.fit(X,y, validation_split = 0.33, epochs = 150, batch_size = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section2.2\"></a>\n",
    "# <font color=\"#004D7F\" size=5>2.2. Verificación manual</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras también le permite especificar manualmente el conjunto de datos que se utilizará para la validación durante el entrenamiento. En este ejemplo usamos la práctica función `train_test_split()` de Scikit-learn usando un 67%/33%. \n",
    "\n",
    "El conjunto de datos de validación se puede especificar a la función `fit()` mediante el argumento `validation_data`. Toma una tupla de los conjuntos de datos de entrada (X) y salida (y).\n",
    "\n",
    "Veamos un ejemplo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 37.0344 - accuracy: 0.6440 - val_loss: 21.0684 - val_accuracy: 0.6575\n",
      "Epoch 2/150\n",
      "52/52 [==============================] - 0s 933us/step - loss: 9.8370 - accuracy: 0.5156 - val_loss: 3.9511 - val_accuracy: 0.4449\n",
      "Epoch 3/150\n",
      "52/52 [==============================] - 0s 908us/step - loss: 3.3669 - accuracy: 0.4942 - val_loss: 2.6469 - val_accuracy: 0.5236\n",
      "Epoch 4/150\n",
      "52/52 [==============================] - 0s 915us/step - loss: 2.2253 - accuracy: 0.5078 - val_loss: 1.5883 - val_accuracy: 0.5669\n",
      "Epoch 5/150\n",
      "52/52 [==============================] - 0s 904us/step - loss: 1.3591 - accuracy: 0.5175 - val_loss: 1.0437 - val_accuracy: 0.6102\n",
      "Epoch 6/150\n",
      "52/52 [==============================] - 0s 927us/step - loss: 1.0974 - accuracy: 0.5467 - val_loss: 0.9789 - val_accuracy: 0.5984\n",
      "Epoch 7/150\n",
      "52/52 [==============================] - 0s 946us/step - loss: 1.0517 - accuracy: 0.5525 - val_loss: 0.9883 - val_accuracy: 0.6102\n",
      "Epoch 8/150\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.9959 - accuracy: 0.5409 - val_loss: 0.9004 - val_accuracy: 0.5669\n",
      "Epoch 9/150\n",
      "52/52 [==============================] - 0s 951us/step - loss: 0.9752 - accuracy: 0.5759 - val_loss: 0.8638 - val_accuracy: 0.5827\n",
      "Epoch 10/150\n",
      "52/52 [==============================] - 0s 887us/step - loss: 0.8919 - accuracy: 0.5661 - val_loss: 0.8816 - val_accuracy: 0.5906\n",
      "Epoch 11/150\n",
      "52/52 [==============================] - 0s 934us/step - loss: 0.8627 - accuracy: 0.5642 - val_loss: 0.8294 - val_accuracy: 0.5866\n",
      "Epoch 12/150\n",
      "52/52 [==============================] - 0s 945us/step - loss: 0.8329 - accuracy: 0.5837 - val_loss: 0.8232 - val_accuracy: 0.5866\n",
      "Epoch 13/150\n",
      "52/52 [==============================] - 0s 910us/step - loss: 0.8303 - accuracy: 0.5895 - val_loss: 0.8080 - val_accuracy: 0.5945\n",
      "Epoch 14/150\n",
      "52/52 [==============================] - 0s 915us/step - loss: 0.7873 - accuracy: 0.6167 - val_loss: 0.7939 - val_accuracy: 0.5748\n",
      "Epoch 15/150\n",
      "52/52 [==============================] - 0s 943us/step - loss: 0.7871 - accuracy: 0.6070 - val_loss: 0.7755 - val_accuracy: 0.6024\n",
      "Epoch 16/150\n",
      "52/52 [==============================] - 0s 938us/step - loss: 0.7603 - accuracy: 0.6226 - val_loss: 0.7793 - val_accuracy: 0.5827\n",
      "Epoch 17/150\n",
      "52/52 [==============================] - 0s 958us/step - loss: 0.7662 - accuracy: 0.6401 - val_loss: 0.7535 - val_accuracy: 0.6142\n",
      "Epoch 18/150\n",
      "52/52 [==============================] - 0s 951us/step - loss: 0.7334 - accuracy: 0.6167 - val_loss: 0.8046 - val_accuracy: 0.6063\n",
      "Epoch 19/150\n",
      "52/52 [==============================] - 0s 932us/step - loss: 0.7092 - accuracy: 0.6518 - val_loss: 0.7367 - val_accuracy: 0.6102\n",
      "Epoch 20/150\n",
      "52/52 [==============================] - 0s 907us/step - loss: 0.7267 - accuracy: 0.6089 - val_loss: 0.7369 - val_accuracy: 0.6339\n",
      "Epoch 21/150\n",
      "52/52 [==============================] - 0s 909us/step - loss: 0.7105 - accuracy: 0.6518 - val_loss: 0.7738 - val_accuracy: 0.6102\n",
      "Epoch 22/150\n",
      "52/52 [==============================] - 0s 881us/step - loss: 0.6906 - accuracy: 0.6518 - val_loss: 0.7625 - val_accuracy: 0.6260\n",
      "Epoch 23/150\n",
      "52/52 [==============================] - 0s 914us/step - loss: 0.6899 - accuracy: 0.6498 - val_loss: 0.7178 - val_accuracy: 0.6496\n",
      "Epoch 24/150\n",
      "52/52 [==============================] - 0s 934us/step - loss: 0.7165 - accuracy: 0.6304 - val_loss: 0.7098 - val_accuracy: 0.6535\n",
      "Epoch 25/150\n",
      "52/52 [==============================] - 0s 876us/step - loss: 0.6786 - accuracy: 0.6498 - val_loss: 0.8056 - val_accuracy: 0.6260\n",
      "Epoch 26/150\n",
      "52/52 [==============================] - 0s 877us/step - loss: 0.6674 - accuracy: 0.6498 - val_loss: 0.6991 - val_accuracy: 0.6220\n",
      "Epoch 27/150\n",
      "52/52 [==============================] - 0s 867us/step - loss: 0.6671 - accuracy: 0.6479 - val_loss: 0.7096 - val_accuracy: 0.6181\n",
      "Epoch 28/150\n",
      "52/52 [==============================] - 0s 907us/step - loss: 0.7203 - accuracy: 0.6109 - val_loss: 0.7456 - val_accuracy: 0.6102\n",
      "Epoch 29/150\n",
      "52/52 [==============================] - 0s 918us/step - loss: 0.6642 - accuracy: 0.6634 - val_loss: 0.6948 - val_accuracy: 0.6181\n",
      "Epoch 30/150\n",
      "52/52 [==============================] - 0s 978us/step - loss: 0.6690 - accuracy: 0.6440 - val_loss: 0.7178 - val_accuracy: 0.6220\n",
      "Epoch 31/150\n",
      "52/52 [==============================] - 0s 997us/step - loss: 0.6727 - accuracy: 0.6304 - val_loss: 0.7197 - val_accuracy: 0.6260\n",
      "Epoch 32/150\n",
      "52/52 [==============================] - 0s 940us/step - loss: 0.6641 - accuracy: 0.6712 - val_loss: 0.7382 - val_accuracy: 0.6181\n",
      "Epoch 33/150\n",
      "52/52 [==============================] - 0s 931us/step - loss: 0.6835 - accuracy: 0.6556 - val_loss: 0.6822 - val_accuracy: 0.6732\n",
      "Epoch 34/150\n",
      "52/52 [==============================] - 0s 981us/step - loss: 0.6402 - accuracy: 0.6615 - val_loss: 0.7388 - val_accuracy: 0.6378\n",
      "Epoch 35/150\n",
      "52/52 [==============================] - 0s 923us/step - loss: 0.6426 - accuracy: 0.6537 - val_loss: 0.6765 - val_accuracy: 0.6693\n",
      "Epoch 36/150\n",
      "52/52 [==============================] - 0s 939us/step - loss: 0.6336 - accuracy: 0.6732 - val_loss: 0.6665 - val_accuracy: 0.6457\n",
      "Epoch 37/150\n",
      "52/52 [==============================] - 0s 905us/step - loss: 0.6256 - accuracy: 0.6790 - val_loss: 0.6853 - val_accuracy: 0.6496\n",
      "Epoch 38/150\n",
      "52/52 [==============================] - 0s 865us/step - loss: 0.6232 - accuracy: 0.6907 - val_loss: 0.6840 - val_accuracy: 0.6339\n",
      "Epoch 39/150\n",
      "52/52 [==============================] - 0s 938us/step - loss: 0.6368 - accuracy: 0.6770 - val_loss: 0.6583 - val_accuracy: 0.6614\n",
      "Epoch 40/150\n",
      "52/52 [==============================] - 0s 898us/step - loss: 0.6436 - accuracy: 0.6732 - val_loss: 0.7374 - val_accuracy: 0.5984\n",
      "Epoch 41/150\n",
      "52/52 [==============================] - 0s 919us/step - loss: 0.6370 - accuracy: 0.6673 - val_loss: 0.6762 - val_accuracy: 0.6378\n",
      "Epoch 42/150\n",
      "52/52 [==============================] - 0s 883us/step - loss: 0.6290 - accuracy: 0.6809 - val_loss: 0.6763 - val_accuracy: 0.6732\n",
      "Epoch 43/150\n",
      "52/52 [==============================] - 0s 873us/step - loss: 0.6243 - accuracy: 0.6887 - val_loss: 0.6635 - val_accuracy: 0.6850\n",
      "Epoch 44/150\n",
      "52/52 [==============================] - 0s 905us/step - loss: 0.6410 - accuracy: 0.6907 - val_loss: 0.7331 - val_accuracy: 0.6339\n",
      "Epoch 45/150\n",
      "52/52 [==============================] - 0s 913us/step - loss: 0.6666 - accuracy: 0.7004 - val_loss: 0.6862 - val_accuracy: 0.6457\n",
      "Epoch 46/150\n",
      "52/52 [==============================] - 0s 900us/step - loss: 0.6175 - accuracy: 0.6868 - val_loss: 0.6572 - val_accuracy: 0.6260\n",
      "Epoch 47/150\n",
      "52/52 [==============================] - 0s 886us/step - loss: 0.6463 - accuracy: 0.6712 - val_loss: 0.7167 - val_accuracy: 0.6417\n",
      "Epoch 48/150\n",
      "52/52 [==============================] - 0s 871us/step - loss: 0.6488 - accuracy: 0.6712 - val_loss: 0.6563 - val_accuracy: 0.6850\n",
      "Epoch 49/150\n",
      "52/52 [==============================] - 0s 896us/step - loss: 0.6330 - accuracy: 0.6673 - val_loss: 0.6816 - val_accuracy: 0.6496\n",
      "Epoch 50/150\n",
      "52/52 [==============================] - 0s 890us/step - loss: 0.6220 - accuracy: 0.6868 - val_loss: 0.6487 - val_accuracy: 0.6850\n",
      "Epoch 51/150\n",
      "52/52 [==============================] - 0s 924us/step - loss: 0.5994 - accuracy: 0.7004 - val_loss: 0.6536 - val_accuracy: 0.6614\n",
      "Epoch 52/150\n",
      "52/52 [==============================] - 0s 854us/step - loss: 0.6198 - accuracy: 0.6887 - val_loss: 0.6941 - val_accuracy: 0.6654\n",
      "Epoch 53/150\n",
      "52/52 [==============================] - 0s 894us/step - loss: 0.6110 - accuracy: 0.6984 - val_loss: 0.6770 - val_accuracy: 0.6378\n",
      "Epoch 54/150\n",
      "52/52 [==============================] - 0s 942us/step - loss: 0.6517 - accuracy: 0.6868 - val_loss: 0.7248 - val_accuracy: 0.6063\n",
      "Epoch 55/150\n",
      "52/52 [==============================] - 0s 953us/step - loss: 0.6013 - accuracy: 0.6848 - val_loss: 0.6533 - val_accuracy: 0.6969\n",
      "Epoch 56/150\n",
      "52/52 [==============================] - 0s 979us/step - loss: 0.6572 - accuracy: 0.6459 - val_loss: 0.7331 - val_accuracy: 0.6220\n",
      "Epoch 57/150\n",
      "52/52 [==============================] - 0s 971us/step - loss: 0.6073 - accuracy: 0.6829 - val_loss: 0.6787 - val_accuracy: 0.6417\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/150\n",
      "52/52 [==============================] - 0s 959us/step - loss: 0.5988 - accuracy: 0.7101 - val_loss: 0.6841 - val_accuracy: 0.6614\n",
      "Epoch 59/150\n",
      "52/52 [==============================] - 0s 911us/step - loss: 0.5989 - accuracy: 0.6946 - val_loss: 0.6632 - val_accuracy: 0.6654\n",
      "Epoch 60/150\n",
      "52/52 [==============================] - 0s 888us/step - loss: 0.5930 - accuracy: 0.7121 - val_loss: 0.6642 - val_accuracy: 0.6496\n",
      "Epoch 61/150\n",
      "52/52 [==============================] - 0s 903us/step - loss: 0.6352 - accuracy: 0.6770 - val_loss: 0.6811 - val_accuracy: 0.6417\n",
      "Epoch 62/150\n",
      "52/52 [==============================] - 0s 879us/step - loss: 0.5909 - accuracy: 0.6946 - val_loss: 0.6856 - val_accuracy: 0.6457\n",
      "Epoch 63/150\n",
      "52/52 [==============================] - 0s 925us/step - loss: 0.6191 - accuracy: 0.6868 - val_loss: 0.6935 - val_accuracy: 0.6496\n",
      "Epoch 64/150\n",
      "52/52 [==============================] - 0s 928us/step - loss: 0.5768 - accuracy: 0.7276 - val_loss: 0.6927 - val_accuracy: 0.6457\n",
      "Epoch 65/150\n",
      "52/52 [==============================] - 0s 996us/step - loss: 0.6047 - accuracy: 0.7121 - val_loss: 0.7516 - val_accuracy: 0.5787\n",
      "Epoch 66/150\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.6268 - accuracy: 0.6693 - val_loss: 0.6488 - val_accuracy: 0.7047\n",
      "Epoch 67/150\n",
      "52/52 [==============================] - 0s 933us/step - loss: 0.6058 - accuracy: 0.6809 - val_loss: 0.6492 - val_accuracy: 0.6654\n",
      "Epoch 68/150\n",
      "52/52 [==============================] - 0s 912us/step - loss: 0.5913 - accuracy: 0.7023 - val_loss: 0.7495 - val_accuracy: 0.6575\n",
      "Epoch 69/150\n",
      "52/52 [==============================] - 0s 914us/step - loss: 0.6324 - accuracy: 0.6809 - val_loss: 0.6478 - val_accuracy: 0.6929\n",
      "Epoch 70/150\n",
      "52/52 [==============================] - 0s 989us/step - loss: 0.6242 - accuracy: 0.6595 - val_loss: 0.6448 - val_accuracy: 0.7008\n",
      "Epoch 71/150\n",
      "52/52 [==============================] - 0s 952us/step - loss: 0.5935 - accuracy: 0.7004 - val_loss: 0.7301 - val_accuracy: 0.6496\n",
      "Epoch 72/150\n",
      "52/52 [==============================] - 0s 882us/step - loss: 0.6016 - accuracy: 0.7140 - val_loss: 0.6505 - val_accuracy: 0.6575\n",
      "Epoch 73/150\n",
      "52/52 [==============================] - 0s 921us/step - loss: 0.5953 - accuracy: 0.7082 - val_loss: 0.6921 - val_accuracy: 0.6654\n",
      "Epoch 74/150\n",
      "52/52 [==============================] - 0s 943us/step - loss: 0.5855 - accuracy: 0.6887 - val_loss: 0.6568 - val_accuracy: 0.7087\n",
      "Epoch 75/150\n",
      "52/52 [==============================] - 0s 914us/step - loss: 0.5827 - accuracy: 0.6965 - val_loss: 0.6458 - val_accuracy: 0.6890\n",
      "Epoch 76/150\n",
      "52/52 [==============================] - 0s 929us/step - loss: 0.5792 - accuracy: 0.7043 - val_loss: 0.6544 - val_accuracy: 0.6654\n",
      "Epoch 77/150\n",
      "52/52 [==============================] - 0s 907us/step - loss: 0.5860 - accuracy: 0.7004 - val_loss: 0.6366 - val_accuracy: 0.7087\n",
      "Epoch 78/150\n",
      "52/52 [==============================] - 0s 892us/step - loss: 0.5831 - accuracy: 0.6887 - val_loss: 0.6382 - val_accuracy: 0.6732\n",
      "Epoch 79/150\n",
      "52/52 [==============================] - 0s 883us/step - loss: 0.5769 - accuracy: 0.7101 - val_loss: 0.6320 - val_accuracy: 0.7126\n",
      "Epoch 80/150\n",
      "52/52 [==============================] - 0s 877us/step - loss: 0.5840 - accuracy: 0.6946 - val_loss: 0.6394 - val_accuracy: 0.6890\n",
      "Epoch 81/150\n",
      "52/52 [==============================] - 0s 929us/step - loss: 0.5725 - accuracy: 0.7023 - val_loss: 0.6390 - val_accuracy: 0.7165\n",
      "Epoch 82/150\n",
      "52/52 [==============================] - 0s 884us/step - loss: 0.5717 - accuracy: 0.7004 - val_loss: 0.6480 - val_accuracy: 0.7087\n",
      "Epoch 83/150\n",
      "52/52 [==============================] - 0s 884us/step - loss: 0.6007 - accuracy: 0.6926 - val_loss: 0.6422 - val_accuracy: 0.7165\n",
      "Epoch 84/150\n",
      "52/52 [==============================] - 0s 871us/step - loss: 0.5646 - accuracy: 0.7198 - val_loss: 0.6480 - val_accuracy: 0.6575\n",
      "Epoch 85/150\n",
      "52/52 [==============================] - 0s 908us/step - loss: 0.5762 - accuracy: 0.7140 - val_loss: 0.7602 - val_accuracy: 0.6614\n",
      "Epoch 86/150\n",
      "52/52 [==============================] - 0s 904us/step - loss: 0.5647 - accuracy: 0.7121 - val_loss: 0.6621 - val_accuracy: 0.6929\n",
      "Epoch 87/150\n",
      "52/52 [==============================] - 0s 886us/step - loss: 0.5661 - accuracy: 0.7276 - val_loss: 0.6682 - val_accuracy: 0.6732\n",
      "Epoch 88/150\n",
      "52/52 [==============================] - 0s 902us/step - loss: 0.5869 - accuracy: 0.6868 - val_loss: 0.6412 - val_accuracy: 0.6811\n",
      "Epoch 89/150\n",
      "52/52 [==============================] - 0s 893us/step - loss: 0.5677 - accuracy: 0.7315 - val_loss: 0.6801 - val_accuracy: 0.6772\n",
      "Epoch 90/150\n",
      "52/52 [==============================] - 0s 899us/step - loss: 0.5724 - accuracy: 0.7082 - val_loss: 0.6754 - val_accuracy: 0.6890\n",
      "Epoch 91/150\n",
      "52/52 [==============================] - 0s 911us/step - loss: 0.5728 - accuracy: 0.7062 - val_loss: 0.6822 - val_accuracy: 0.6693\n",
      "Epoch 92/150\n",
      "52/52 [==============================] - 0s 960us/step - loss: 0.5981 - accuracy: 0.6887 - val_loss: 0.6372 - val_accuracy: 0.6890\n",
      "Epoch 93/150\n",
      "52/52 [==============================] - 0s 907us/step - loss: 0.5592 - accuracy: 0.7121 - val_loss: 0.6355 - val_accuracy: 0.7047\n",
      "Epoch 94/150\n",
      "52/52 [==============================] - 0s 884us/step - loss: 0.5513 - accuracy: 0.7490 - val_loss: 0.6411 - val_accuracy: 0.6969\n",
      "Epoch 95/150\n",
      "52/52 [==============================] - 0s 932us/step - loss: 0.5938 - accuracy: 0.7101 - val_loss: 0.6367 - val_accuracy: 0.6850\n",
      "Epoch 96/150\n",
      "52/52 [==============================] - 0s 903us/step - loss: 0.5693 - accuracy: 0.6984 - val_loss: 0.6358 - val_accuracy: 0.7087\n",
      "Epoch 97/150\n",
      "52/52 [==============================] - 0s 884us/step - loss: 0.5904 - accuracy: 0.6926 - val_loss: 0.6364 - val_accuracy: 0.7047\n",
      "Epoch 98/150\n",
      "52/52 [==============================] - 0s 930us/step - loss: 0.5669 - accuracy: 0.7198 - val_loss: 0.6347 - val_accuracy: 0.7244\n",
      "Epoch 99/150\n",
      "52/52 [==============================] - 0s 988us/step - loss: 0.5574 - accuracy: 0.7160 - val_loss: 0.6490 - val_accuracy: 0.6811\n",
      "Epoch 100/150\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.5818 - accuracy: 0.6887 - val_loss: 0.6365 - val_accuracy: 0.7165\n",
      "Epoch 101/150\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.5673 - accuracy: 0.7160 - val_loss: 0.6232 - val_accuracy: 0.7126\n",
      "Epoch 102/150\n",
      "52/52 [==============================] - 0s 978us/step - loss: 0.5648 - accuracy: 0.7237 - val_loss: 0.6200 - val_accuracy: 0.7205\n",
      "Epoch 103/150\n",
      "52/52 [==============================] - 0s 940us/step - loss: 0.5508 - accuracy: 0.7218 - val_loss: 0.6314 - val_accuracy: 0.6811\n",
      "Epoch 104/150\n",
      "52/52 [==============================] - 0s 938us/step - loss: 0.5595 - accuracy: 0.7257 - val_loss: 0.6330 - val_accuracy: 0.7205\n",
      "Epoch 105/150\n",
      "52/52 [==============================] - 0s 938us/step - loss: 0.5706 - accuracy: 0.7140 - val_loss: 0.6677 - val_accuracy: 0.6850\n",
      "Epoch 106/150\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.5748 - accuracy: 0.7354 - val_loss: 0.6292 - val_accuracy: 0.7283\n",
      "Epoch 107/150\n",
      "52/52 [==============================] - 0s 997us/step - loss: 0.5542 - accuracy: 0.7237 - val_loss: 0.6527 - val_accuracy: 0.6772\n",
      "Epoch 108/150\n",
      "52/52 [==============================] - 0s 959us/step - loss: 0.5525 - accuracy: 0.7296 - val_loss: 0.6433 - val_accuracy: 0.7165\n",
      "Epoch 109/150\n",
      "52/52 [==============================] - 0s 926us/step - loss: 0.5631 - accuracy: 0.7296 - val_loss: 0.6379 - val_accuracy: 0.7205\n",
      "Epoch 110/150\n",
      "52/52 [==============================] - 0s 978us/step - loss: 0.5663 - accuracy: 0.7315 - val_loss: 0.6300 - val_accuracy: 0.7402\n",
      "Epoch 111/150\n",
      "52/52 [==============================] - 0s 940us/step - loss: 0.5536 - accuracy: 0.7257 - val_loss: 0.6274 - val_accuracy: 0.7205\n",
      "Epoch 112/150\n",
      "52/52 [==============================] - 0s 978us/step - loss: 0.5442 - accuracy: 0.7160 - val_loss: 0.6367 - val_accuracy: 0.7362\n",
      "Epoch 113/150\n",
      "52/52 [==============================] - 0s 921us/step - loss: 0.5515 - accuracy: 0.7160 - val_loss: 0.6597 - val_accuracy: 0.6693\n",
      "Epoch 114/150\n",
      "52/52 [==============================] - 0s 959us/step - loss: 0.5686 - accuracy: 0.7062 - val_loss: 0.6989 - val_accuracy: 0.6339\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 115/150\n",
      "52/52 [==============================] - 0s 940us/step - loss: 0.5650 - accuracy: 0.7023 - val_loss: 0.6550 - val_accuracy: 0.7008\n",
      "Epoch 116/150\n",
      "52/52 [==============================] - 0s 997us/step - loss: 0.5419 - accuracy: 0.7218 - val_loss: 0.6681 - val_accuracy: 0.6772\n",
      "Epoch 117/150\n",
      "52/52 [==============================] - 0s 902us/step - loss: 0.5715 - accuracy: 0.7179 - val_loss: 0.6308 - val_accuracy: 0.7008\n",
      "Epoch 118/150\n",
      "52/52 [==============================] - 0s 901us/step - loss: 0.5611 - accuracy: 0.7218 - val_loss: 0.6896 - val_accuracy: 0.6575\n",
      "Epoch 119/150\n",
      "52/52 [==============================] - 0s 882us/step - loss: 0.6121 - accuracy: 0.6946 - val_loss: 0.6341 - val_accuracy: 0.7362\n",
      "Epoch 120/150\n",
      "52/52 [==============================] - 0s 885us/step - loss: 0.5491 - accuracy: 0.7276 - val_loss: 0.6281 - val_accuracy: 0.7008\n",
      "Epoch 121/150\n",
      "52/52 [==============================] - 0s 849us/step - loss: 0.5354 - accuracy: 0.7315 - val_loss: 0.6392 - val_accuracy: 0.7362\n",
      "Epoch 122/150\n",
      "52/52 [==============================] - 0s 884us/step - loss: 0.5664 - accuracy: 0.7218 - val_loss: 0.6364 - val_accuracy: 0.7008\n",
      "Epoch 123/150\n",
      "52/52 [==============================] - 0s 827us/step - loss: 0.5502 - accuracy: 0.7412 - val_loss: 0.6315 - val_accuracy: 0.7126\n",
      "Epoch 124/150\n",
      "52/52 [==============================] - 0s 893us/step - loss: 0.5422 - accuracy: 0.7354 - val_loss: 0.6275 - val_accuracy: 0.7362\n",
      "Epoch 125/150\n",
      "52/52 [==============================] - 0s 923us/step - loss: 0.5402 - accuracy: 0.7432 - val_loss: 0.6286 - val_accuracy: 0.7205\n",
      "Epoch 126/150\n",
      "52/52 [==============================] - 0s 931us/step - loss: 0.5615 - accuracy: 0.7296 - val_loss: 0.6070 - val_accuracy: 0.7126\n",
      "Epoch 127/150\n",
      "52/52 [==============================] - 0s 921us/step - loss: 0.5436 - accuracy: 0.7529 - val_loss: 0.6127 - val_accuracy: 0.7047\n",
      "Epoch 128/150\n",
      "52/52 [==============================] - 0s 902us/step - loss: 0.5491 - accuracy: 0.7296 - val_loss: 0.7347 - val_accuracy: 0.6575\n",
      "Epoch 129/150\n",
      "52/52 [==============================] - 0s 959us/step - loss: 0.5654 - accuracy: 0.7198 - val_loss: 0.6308 - val_accuracy: 0.6850\n",
      "Epoch 130/150\n",
      "52/52 [==============================] - 0s 921us/step - loss: 0.5373 - accuracy: 0.7549 - val_loss: 0.6314 - val_accuracy: 0.6890\n",
      "Epoch 131/150\n",
      "52/52 [==============================] - 0s 901us/step - loss: 0.5400 - accuracy: 0.7218 - val_loss: 0.6965 - val_accuracy: 0.6693\n",
      "Epoch 132/150\n",
      "52/52 [==============================] - 0s 901us/step - loss: 0.5548 - accuracy: 0.7121 - val_loss: 0.6251 - val_accuracy: 0.7283\n",
      "Epoch 133/150\n",
      "52/52 [==============================] - 0s 882us/step - loss: 0.5442 - accuracy: 0.7354 - val_loss: 0.6203 - val_accuracy: 0.7283\n",
      "Epoch 134/150\n",
      "52/52 [==============================] - 0s 939us/step - loss: 0.5484 - accuracy: 0.7374 - val_loss: 0.6590 - val_accuracy: 0.6850\n",
      "Epoch 135/150\n",
      "52/52 [==============================] - 0s 892us/step - loss: 0.5626 - accuracy: 0.7198 - val_loss: 0.6905 - val_accuracy: 0.6732\n",
      "Epoch 136/150\n",
      "52/52 [==============================] - 0s 921us/step - loss: 0.5529 - accuracy: 0.7354 - val_loss: 0.6212 - val_accuracy: 0.7244\n",
      "Epoch 137/150\n",
      "52/52 [==============================] - 0s 901us/step - loss: 0.5385 - accuracy: 0.7354 - val_loss: 0.6287 - val_accuracy: 0.6929\n",
      "Epoch 138/150\n",
      "52/52 [==============================] - 0s 940us/step - loss: 0.5417 - accuracy: 0.7257 - val_loss: 0.6361 - val_accuracy: 0.7402\n",
      "Epoch 139/150\n",
      "52/52 [==============================] - 0s 940us/step - loss: 0.5403 - accuracy: 0.7296 - val_loss: 0.6209 - val_accuracy: 0.7244\n",
      "Epoch 140/150\n",
      "52/52 [==============================] - 0s 940us/step - loss: 0.5292 - accuracy: 0.7354 - val_loss: 0.6232 - val_accuracy: 0.7205\n",
      "Epoch 141/150\n",
      "52/52 [==============================] - 0s 892us/step - loss: 0.5721 - accuracy: 0.7062 - val_loss: 0.6216 - val_accuracy: 0.7283\n",
      "Epoch 142/150\n",
      "52/52 [==============================] - 0s 841us/step - loss: 0.5633 - accuracy: 0.7160 - val_loss: 0.6232 - val_accuracy: 0.7362\n",
      "Epoch 143/150\n",
      "52/52 [==============================] - 0s 901us/step - loss: 0.5330 - accuracy: 0.7412 - val_loss: 0.6458 - val_accuracy: 0.6890\n",
      "Epoch 144/150\n",
      "52/52 [==============================] - 0s 918us/step - loss: 0.5324 - accuracy: 0.7354 - val_loss: 0.6203 - val_accuracy: 0.7441\n",
      "Epoch 145/150\n",
      "52/52 [==============================] - 0s 909us/step - loss: 0.5243 - accuracy: 0.7665 - val_loss: 0.6465 - val_accuracy: 0.7283\n",
      "Epoch 146/150\n",
      "52/52 [==============================] - 0s 871us/step - loss: 0.5464 - accuracy: 0.7374 - val_loss: 0.6253 - val_accuracy: 0.7244\n",
      "Epoch 147/150\n",
      "52/52 [==============================] - 0s 859us/step - loss: 0.5391 - accuracy: 0.7451 - val_loss: 0.6254 - val_accuracy: 0.7323\n",
      "Epoch 148/150\n",
      "52/52 [==============================] - 0s 899us/step - loss: 0.5292 - accuracy: 0.7276 - val_loss: 0.6512 - val_accuracy: 0.7165\n",
      "Epoch 149/150\n",
      "52/52 [==============================] - 0s 914us/step - loss: 0.5349 - accuracy: 0.7471 - val_loss: 0.6270 - val_accuracy: 0.7205\n",
      "Epoch 150/150\n",
      "52/52 [==============================] - 0s 901us/step - loss: 0.5397 - accuracy: 0.7354 - val_loss: 0.6296 - val_accuracy: 0.7244\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1d97e4cb790>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MLP with manual validation set\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# load pima indians dataset\n",
    "ruta = \"C:/Users/Maria Luisa/OneDrive/Documentos/Cursos/DeepLearningConPythonyKerasRedesNeuronalesAvanzado/Datasets/pima-indians-diabetes.csv\"\n",
    "dataset = np.loadtxt(ruta, delimiter = ',')\n",
    "\n",
    "# split into input (X) and output (Y) variables\n",
    "X = dataset[:, 0:8]\n",
    "y = dataset[:,8]\n",
    "\n",
    "# split into 67% for train and 33% for test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.33)\n",
    "\n",
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim = 8, activation = 'relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation= 'sigmoid'))\n",
    "\n",
    "# Compile model\n",
    "model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "\n",
    "# Fit the model\n",
    "model.fit(X_train, y_train, validation_data = (X_test, y_test), epochs =150, batch_size =10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<div style=\"text-align: right\"> <font size=5> <a href=\"#indice\"><i class=\"fa fa-arrow-circle-up\" aria-hidden=\"true\" style=\"color:#004D7F\"></i></a></font></div>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section3\"></a>\n",
    "# <font color=\"#004D7F\" size=6>3. Validación cruzada</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La validación cruzada a menudo no se usa para evaluar modelos de aprendizaje profundo debido al mayor gasto computacional, demasiadas iteraciones para modelos muy pesados.\n",
    "\n",
    "En el siguiente ejemplo, usamos el práctico clase `StratifiedKFold` de scikit-learn para dividir el conjunto de datos de entrenamiento en 10-folds. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 72.73% \n",
      "accuracy : 64.94% \n",
      "accuracy : 67.53% \n",
      "accuracy : 77.92% \n",
      "accuracy : 64.94% \n",
      "accuracy : 58.44% \n",
      "accuracy : 75.32% \n",
      "accuracy : 76.62% \n",
      "accuracy : 77.63% \n",
      "accuracy : 73.68% \n",
      "70.98% (+/- 6.29%)\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import numpy as np \n",
    "\n",
    "# load pima indians dataset\n",
    "ruta = \"C:/Users/Maria Luisa/OneDrive/Documentos/Cursos/DeepLearningConPythonyKerasRedesNeuronalesAvanzado/Datasets/pima-indians-diabetes.csv\"\n",
    "dataset = np.loadtxt(ruta, delimiter = ',')\n",
    "\n",
    "# split into input (X) and output (Y) variables\n",
    "X = dataset[:, 0:8]\n",
    "y = dataset[:,8]\n",
    "\n",
    "\n",
    "# define 10-fold cross validation test harness\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle = True, random_state=7)\n",
    "cvscores = []\n",
    "for train,test in kfold.split(X,y):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(12, input_dim = 8, activation = 'relu'))\n",
    "    model.add(Dense(8, activation='relu'))\n",
    "    model.add(Dense(1, activation= 'sigmoid'))\n",
    "    #compile model\n",
    "    model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "    #fit the model\n",
    "    model.fit(X[train], y[train], epochs = 150, batch_size =10, verbose = 0)\n",
    "    #evaluate the model\n",
    "    scores = model.evaluate(X[test], y[test], verbose =0)\n",
    "    print(\"%s : %.2f%% \" % (model.metrics_names[1], scores[1]*100))\n",
    "    cvscores.append(scores[1]*100)\n",
    "#print the global results\n",
    "print(\"%.2f%% (+/- %.2f%%)\" %(np.mean(cvscores), np.std(cvscores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "<i class=\"fa fa-info-circle\" aria-hidden=\"true\"></i>\n",
    "Se ha tenido que volver a crear el modelo en cada bucle para luego ajustarlo y evaluarlo con los datos del fold. En la próxima lección veremos cómo podemos usar los modelos de Keras de forma nativa con Scikit-learn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: right\"> <font size=5> <a href=\"#indice\"><i class=\"fa fa-arrow-circle-up\" aria-hidden=\"true\" style=\"color:#004D7F\"></i></a></font></div>\n",
    "\n",
    "---\n",
    "\n",
    "<div style=\"text-align: right\"> <font size=6><i class=\"fa fa-coffee\" aria-hidden=\"true\" style=\"color:#004D7F\"></i> </font></div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
